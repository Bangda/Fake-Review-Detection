{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import swifter\n",
    "import re\n",
    "import string\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# import classifiers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, svm\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score, classification_report, roc_curve, auc, accuracy_score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle('../data/processed_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YR    223414\n",
       "NR    187966\n",
       "Name: flagged, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.flagged.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[df['flagged'] == 'YR', 'flagged'] = 1\n",
    "df.loc[df['flagged'] == 'NR', 'flagged'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(329104,)\n",
      "(82276,)\n"
     ]
    }
   ],
   "source": [
    "# take the processed_text column as training data\n",
    "X = df.processed_text\n",
    "y = df.flagged\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# examine the object shapes\n",
    "print(train_x.shape)\n",
    "print(valid_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    178833\n",
       "0    150271\n",
       "Name: flagged, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count vector as feature\n",
    "vectorize the processed text data using countvectorizer and tfidf vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word')\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.fit_transform(train_x)\n",
    "xvalid_count =  count_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', max_features=30000)\n",
    "xtrain_tfidf =  tfidf_vect.fit_transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', ngram_range=(2,3), max_features=30000)\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.fit_transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
    "\n",
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', ngram_range=(2,3), max_features=30000)\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.fit_transform(train_x) \n",
    "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial model experiment\n",
    "This part aims to test the accuracy of different vectorizer using multiple classifier models, namely, naive bayes classifier and logistic regression. We want to get a general sense how good are the word embeddings fitting the processed text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.648962030239681\n",
      "NB, WordLevel TF-IDF:  0.652438135057611\n",
      "NB, N-Gram Vectors:  0.6211167290582916\n",
      "NB, CharLevel Vectors:  0.6066653702173174\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
    "print (\"NB, Count Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print (\"NB, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print (\"NB, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print (\"NB, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BD\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\BD\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, Count Vectors:  0.6476250668481696\n",
      "LR, WordLevel TF-IDF:  0.6573848996062035\n",
      "LR, N-Gram Vectors:  0.6170329136078565\n",
      "LR, CharLevel Vectors:  0.6408794788273615\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Count Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xvalid_count)\n",
    "print (\"LR, Count Vectors: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print (\"LR, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print (\"LR, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Character Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print (\"LR, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using multinomialNB classifier, countervectorizer gives the highest accuracy followed by wordlevel tfidf. \n",
    "Using logistic regression, wordlevel tfidf gives the highest accuracy, followed by character level, then countvectorizer.\n",
    "\n",
    "It is hard to reach a conclusion whether to use Countervectorizer or TDIDFvectorizer to perform word embedding. Each vectorizer has a set of parameters which if tuned properly, can improve the model performance. Hence, we will proceed to tune each model using the same classifier and compare the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'clf']\n",
      "parameters:\n",
      "{'tfidf__norm': ['l1', 'l2', None]}\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:  1.8min remaining:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 189.435s\n",
      "\n",
      "Best score: 0.634\n",
      "Best parameters set:\n",
      "\ttfidf__norm: 'l2'\n"
     ]
    }
   ],
   "source": [
    "# #############################################################################\n",
    "# normalization term\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "    'tfidf__norm': ['l1', 'l2', None]}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(train_x, train_y)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'clf']\n",
      "parameters:\n",
      "{'tfidf__ngram_range': [(1, 1), (1, 2)]}\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 150.539s\n",
      "\n",
      "Best score: 0.634\n",
      "Best parameters set:\n",
      "\ttfidf__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# #############################################################################\n",
    "# normalization term\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(norm='l2')),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)]}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(train_x, train_y)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'clf']\n",
      "parameters:\n",
      "{'tfidf__max_df': [0.25, 0.5, 0.75], 'tfidf__min_df': (1, 3, 5, 10)}\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:  6.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 414.242s\n",
      "\n",
      "Best score: 0.648\n",
      "Best parameters set:\n",
      "\ttfidf__max_df: 0.75\n",
      "\ttfidf__min_df: 5\n"
     ]
    }
   ],
   "source": [
    "# min_df and max_df\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(norm='l2', ngram_range=(1, 1))),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__min_df': (1, 3, 5, 10),\n",
    "    'tfidf__max_df': [0.25, 0.5, 0.75]}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(train_x, train_y)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'clf']\n",
      "parameters:\n",
      "{'tfidf__smooth_idf': [True, False], 'tfidf__sublinear_tf': [True, False]}\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed:  2.0min remaining:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 146.016s\n",
      "\n",
      "Best score: 0.648\n",
      "Best parameters set:\n",
      "\ttfidf__smooth_idf: True\n",
      "\ttfidf__sublinear_tf: False\n"
     ]
    }
   ],
   "source": [
    "# sublinear_tf and sublinear_tf\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(norm='l2', ngram_range=(1, 1), max_df=0.75, min_df=5)),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__sublinear_tf': [True, False],\n",
    "    'tfidf__smooth_idf': [True, False]\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(train_x, train_y)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'clf']\n",
      "parameters:\n",
      "{'tfidf__max_features': [None, 5000, 10000, 20000, 30000]}\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 141.698s\n",
      "\n",
      "Best score: 0.648\n",
      "Best parameters set:\n",
      "\ttfidf__max_features: None\n"
     ]
    }
   ],
   "source": [
    "# max_features\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(norm='l2', ngram_range=(1, 1), max_df=0.75, min_df=5,\n",
    "                             sublinear_tf = False, smooth_idf = True)),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__max_features': [None, 5000, 10000, 20000, 30000]\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(train_x, train_y)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final parameter for TfidfVectorizer is (norm=None, ngram_range=(1, 2),max_df=0.25,min_df=3,sublinear_tf = True, smooth_idf = True).\n",
    "The testing accuracy for this model on MultinomialNB classifier with default parameter is 67.152%.\n",
    "Now, try to put all the parameters together and find the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'clf']\n",
      "parameters:\n",
      "{'tfidf__max_features': [5000, 10000, 20000, 30000]}\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed:  2.6min remaining:   31.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 185.129s\n",
      "\n",
      "Best score: 0.647\n",
      "Best parameters set:\n",
      "\ttfidf__max_features: 30000\n"
     ]
    }
   ],
   "source": [
    "# max_features\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(norm='l2', ngram_range=(1, 1), max_df=0.75, min_df=5,\n",
    "                             sublinear_tf = False, smooth_idf = True)),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__max_features': [5000, 10000, 20000, 30000]\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(train_x, train_y)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'clf']\n",
      "parameters:\n",
      "{'tfidf__max_features': [30000, 50000, 80000]}\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:  1.8min remaining:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 171.170s\n",
      "\n",
      "Best score: 0.648\n",
      "Best parameters set:\n",
      "\ttfidf__max_features: 50000\n"
     ]
    }
   ],
   "source": [
    "# max_features\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(norm='l2', ngram_range=(1, 1), max_df=0.75, min_df=5,\n",
    "                             sublinear_tf = False, smooth_idf = True)),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__max_features': [30000, 50000, 80000]\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(train_x, train_y)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'clf']\n",
      "parameters:\n",
      "{'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)]}\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:  3.7min remaining:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:  8.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 550.082s\n",
      "\n",
      "Best score: 0.648\n",
      "Best parameters set:\n",
      "\ttfidf__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# ngram_range\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(norm='l2', max_df=0.75, min_df=5,max_features = 50000,\n",
    "                             sublinear_tf = False, smooth_idf = True)),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)]\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(train_x, train_y)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'clf']\n",
      "parameters:\n",
      "{'tfidf__max_df': [0.6, 0.75, 0.8], 'tfidf__min_df': (4, 5, 6)}\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 252.014s\n",
      "\n",
      "Best score: 0.648\n",
      "Best parameters set:\n",
      "\ttfidf__max_df: 0.6\n",
      "\ttfidf__min_df: 5\n"
     ]
    }
   ],
   "source": [
    "# min_df and max_df\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(norm='l2',max_features = 50000,ngram_range=(1, 1),\n",
    "                             sublinear_df = False, smooth_idf = True)),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__min_df': (4, 5, 6),\n",
    "    'tfidf__max_df': [0.6, 0.75, 0.8]}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(train_x, train_y)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(norm='l2',max_features = 50000, ngram_range=(1, 1), max_df = 0.6, min_df = 5,\n",
    "                       sublinear_tf = False, smooth_idf = True)\n",
    "train_x_dtm = vect.fit_transform(train_x)\n",
    "valid_x_dtm = vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.43      0.52     37695\n",
      "           1       0.63      0.82      0.71     44581\n",
      "\n",
      "    accuracy                           0.64     82276\n",
      "   macro avg       0.65      0.63      0.62     82276\n",
      "weighted avg       0.65      0.64      0.63     82276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_clf = MultinomialNB(alpha= 10, fit_prior = False)\n",
    "nb_clf.fit(train_x_dtm, train_y)\n",
    "pred_class = nb_clf.predict(valid_x_dtm)\n",
    "pred_prob = nb_clf.predict_proba(valid_x_dtm)\n",
    "print(metrics.classification_report(valid_y, pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.43      0.51     37695\n",
      "           1       0.62      0.78      0.69     44581\n",
      "\n",
      "    accuracy                           0.62     82276\n",
      "   macro avg       0.62      0.61      0.60     82276\n",
      "weighted avg       0.62      0.62      0.61     82276\n",
      "\n",
      "Oveall F1-score:  0.6902682965550087\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "text_clf = Pipeline([\n",
    "                     ('clf', RandomForestClassifier(n_estimators=100)),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(train_x_dtm, train_y)\n",
    "\n",
    "predicted = text_clf.predict(valid_x_dtm)\n",
    "print(metrics.classification_report(valid_y, predicted))\n",
    "print('Oveall F1-score: ', f1_score(valid_y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.47      0.55     37695\n",
      "           1       0.64      0.81      0.72     44581\n",
      "\n",
      "    accuracy                           0.65     82276\n",
      "   macro avg       0.66      0.64      0.63     82276\n",
      "weighted avg       0.66      0.65      0.64     82276\n",
      "\n",
      "Oveall F1-score:  0.7161288400226454\n"
     ]
    }
   ],
   "source": [
    "# MultinomialNB\n",
    "text_clf = Pipeline([\n",
    "                     ('clf', MultinomialNB()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(train_x_dtm, train_y)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(valid_x_dtm)\n",
    "\n",
    "print(metrics.classification_report(valid_y, predicted))\n",
    "print('Oveall F1-score: ', f1_score(valid_y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.32      0.42     37695\n",
      "           1       0.60      0.85      0.70     44581\n",
      "\n",
      "    accuracy                           0.61     82276\n",
      "   macro avg       0.62      0.58      0.56     82276\n",
      "weighted avg       0.62      0.61      0.57     82276\n",
      "\n",
      "Oveall F1-score:  0.7011144322668733\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier\n",
    "text_clf = Pipeline([\n",
    "                     ('clf', GradientBoostingClassifier(n_estimators=100)),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(train_x_dtm, train_y)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(valid_x_dtm)\n",
    "\n",
    "print(metrics.classification_report(valid_y, predicted))\n",
    "print('Oveall F1-score: ', f1_score(valid_y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.45      0.53     37695\n",
      "           1       0.63      0.78      0.70     44581\n",
      "\n",
      "    accuracy                           0.63     82276\n",
      "   macro avg       0.63      0.62      0.61     82276\n",
      "weighted avg       0.63      0.63      0.62     82276\n",
      "\n",
      "Oveall F1-score:  0.6965658585353661\n"
     ]
    }
   ],
   "source": [
    "# XGBClassifier\n",
    "text_clf = Pipeline([\n",
    "                     ('clf', xgb.XGBClassifier()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(train_x_dtm, train_y)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(valid_x_dtm)\n",
    "\n",
    "print(metrics.classification_report(valid_y, predicted))\n",
    "print('Oveall F1-score: ', f1_score(valid_y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
