{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import re\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import swifter\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'reviewID', 'reviewerID', 'reviewContent', 'review_rating',\n",
       "       'review_usefulCount', 'review_coolCount', 'review_funnyCount',\n",
       "       'flagged', 'restaurantID', 'name_x', 'location', 'yelpJoinDate',\n",
       "       'friendCount', 'reviewCount', 'firstCount', 'usefulCount', 'coolCount',\n",
       "       'funnyCount', 'complimentCount', 'tipCount', 'fanCount', 'name_y',\n",
       "       'rating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../data/merged_df.pkl')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>reviewID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewContent</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_usefulCount</th>\n",
       "      <th>review_coolCount</th>\n",
       "      <th>review_funnyCount</th>\n",
       "      <th>flagged</th>\n",
       "      <th>restaurantID</th>\n",
       "      <th>...</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>firstCount</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>coolCount</th>\n",
       "      <th>funnyCount</th>\n",
       "      <th>complimentCount</th>\n",
       "      <th>tipCount</th>\n",
       "      <th>fanCount</th>\n",
       "      <th>name_y</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2012-09-25</td>\n",
       "      <td>xvdJntJlo01tHu83-vXiRw</td>\n",
       "      <td>bNYesZ944s6IJVowOnB0iA</td>\n",
       "      <td>Good choice by our Chicago friends for our fin...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NR</td>\n",
       "      <td>KU_Ze0TpR2HgKG2OpTh2NA</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Slurping Turtle</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2012-06-23</td>\n",
       "      <td>Z4oAUd6mIOhxxDsle3trPA</td>\n",
       "      <td>BSh3h1J4mdSmEsb8FFdf0Q</td>\n",
       "      <td>I'm not a Takashi fan, so I was a bit hesitant...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>YR</td>\n",
       "      <td>KU_Ze0TpR2HgKG2OpTh2NA</td>\n",
       "      <td>...</td>\n",
       "      <td>116</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Slurping Turtle</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>71c7BDude0l5tNjtxRZzMg</td>\n",
       "      <td>XVvbDeYn5Dk-MteNHwjC7Q</td>\n",
       "      <td>I should have read the the 3 stars and below r...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NR</td>\n",
       "      <td>KU_Ze0TpR2HgKG2OpTh2NA</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Slurping Turtle</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                reviewID              reviewerID  \\\n",
       "0 2012-09-25  xvdJntJlo01tHu83-vXiRw  bNYesZ944s6IJVowOnB0iA   \n",
       "1 2012-06-23  Z4oAUd6mIOhxxDsle3trPA  BSh3h1J4mdSmEsb8FFdf0Q   \n",
       "2 2012-10-10  71c7BDude0l5tNjtxRZzMg  XVvbDeYn5Dk-MteNHwjC7Q   \n",
       "\n",
       "                                       reviewContent  review_rating  \\\n",
       "0  Good choice by our Chicago friends for our fin...              4   \n",
       "1  I'm not a Takashi fan, so I was a bit hesitant...              4   \n",
       "2  I should have read the the 3 stars and below r...              2   \n",
       "\n",
       "   review_usefulCount  review_coolCount  review_funnyCount flagged  \\\n",
       "0                   0                 0                  0      NR   \n",
       "1                   0                 0                  0      YR   \n",
       "2                   0                 0                  0      NR   \n",
       "\n",
       "             restaurantID  ... reviewCount firstCount usefulCount  coolCount  \\\n",
       "0  KU_Ze0TpR2HgKG2OpTh2NA  ...          48          5          41          5   \n",
       "1  KU_Ze0TpR2HgKG2OpTh2NA  ...         116          2          93         16   \n",
       "2  KU_Ze0TpR2HgKG2OpTh2NA  ...          14          1           5          1   \n",
       "\n",
       "   funnyCount  complimentCount  tipCount  fanCount           name_y  rating  \n",
       "0           5                2         0         1  Slurping Turtle     3.5  \n",
       "1          19               10         0         2  Slurping Turtle     3.5  \n",
       "2           3                0         4         1  Slurping Turtle     3.5  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MUezNeKlUROw"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>reviewID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewContent</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_usefulCount</th>\n",
       "      <th>review_coolCount</th>\n",
       "      <th>review_funnyCount</th>\n",
       "      <th>flagged</th>\n",
       "      <th>restaurantID</th>\n",
       "      <th>...</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>firstCount</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>coolCount</th>\n",
       "      <th>funnyCount</th>\n",
       "      <th>complimentCount</th>\n",
       "      <th>tipCount</th>\n",
       "      <th>fanCount</th>\n",
       "      <th>name_y</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2012-09-25</td>\n",
       "      <td>xvdJntJlo01tHu83-vXiRw</td>\n",
       "      <td>bNYesZ944s6IJVowOnB0iA</td>\n",
       "      <td>Good choice by our Chicago friends for our fin...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>KU_Ze0TpR2HgKG2OpTh2NA</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Slurping Turtle</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2012-06-23</td>\n",
       "      <td>Z4oAUd6mIOhxxDsle3trPA</td>\n",
       "      <td>BSh3h1J4mdSmEsb8FFdf0Q</td>\n",
       "      <td>I'm not a Takashi fan, so I was a bit hesitant...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>KU_Ze0TpR2HgKG2OpTh2NA</td>\n",
       "      <td>...</td>\n",
       "      <td>116</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Slurping Turtle</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>71c7BDude0l5tNjtxRZzMg</td>\n",
       "      <td>XVvbDeYn5Dk-MteNHwjC7Q</td>\n",
       "      <td>I should have read the the 3 stars and below r...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>KU_Ze0TpR2HgKG2OpTh2NA</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Slurping Turtle</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>Vrzm2xmm2aBqBRqs3yK9Zw</td>\n",
       "      <td>om5ZiponkpRqUNa3pVPiRg</td>\n",
       "      <td>It must be called slurping turtle because thei...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>KU_Ze0TpR2HgKG2OpTh2NA</td>\n",
       "      <td>...</td>\n",
       "      <td>2063</td>\n",
       "      <td>347</td>\n",
       "      <td>12660</td>\n",
       "      <td>9617</td>\n",
       "      <td>6682</td>\n",
       "      <td>6948</td>\n",
       "      <td>605</td>\n",
       "      <td>503</td>\n",
       "      <td>Slurping Turtle</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>coKi6jCbVd4qSUpoE5_0iA</td>\n",
       "      <td>LZt80LbsfQ9kOz96H7c1bA</td>\n",
       "      <td>I'm surprised this place is getting so many ne...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>KU_Ze0TpR2HgKG2OpTh2NA</td>\n",
       "      <td>...</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>84</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>Slurping Turtle</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                reviewID              reviewerID  \\\n",
       "0 2012-09-25  xvdJntJlo01tHu83-vXiRw  bNYesZ944s6IJVowOnB0iA   \n",
       "1 2012-06-23  Z4oAUd6mIOhxxDsle3trPA  BSh3h1J4mdSmEsb8FFdf0Q   \n",
       "2 2012-10-10  71c7BDude0l5tNjtxRZzMg  XVvbDeYn5Dk-MteNHwjC7Q   \n",
       "3 2011-12-15  Vrzm2xmm2aBqBRqs3yK9Zw  om5ZiponkpRqUNa3pVPiRg   \n",
       "4 2012-09-07  coKi6jCbVd4qSUpoE5_0iA  LZt80LbsfQ9kOz96H7c1bA   \n",
       "\n",
       "                                       reviewContent  review_rating  \\\n",
       "0  Good choice by our Chicago friends for our fin...              4   \n",
       "1  I'm not a Takashi fan, so I was a bit hesitant...              4   \n",
       "2  I should have read the the 3 stars and below r...              2   \n",
       "3  It must be called slurping turtle because thei...              3   \n",
       "4  I'm surprised this place is getting so many ne...              4   \n",
       "\n",
       "   review_usefulCount  review_coolCount  review_funnyCount  flagged  \\\n",
       "0                   0                 0                  0        0   \n",
       "1                   0                 0                  0        1   \n",
       "2                   0                 0                  0        0   \n",
       "3                   8                 3                  4        1   \n",
       "4                   2                 2                  1        0   \n",
       "\n",
       "             restaurantID  ... reviewCount firstCount usefulCount  coolCount  \\\n",
       "0  KU_Ze0TpR2HgKG2OpTh2NA  ...          48          5          41          5   \n",
       "1  KU_Ze0TpR2HgKG2OpTh2NA  ...         116          2          93         16   \n",
       "2  KU_Ze0TpR2HgKG2OpTh2NA  ...          14          1           5          1   \n",
       "3  KU_Ze0TpR2HgKG2OpTh2NA  ...        2063        347       12660       9617   \n",
       "4  KU_Ze0TpR2HgKG2OpTh2NA  ...         132          0         154         84   \n",
       "\n",
       "   funnyCount  complimentCount  tipCount  fanCount           name_y  rating  \n",
       "0           5                2         0         1  Slurping Turtle     3.5  \n",
       "1          19               10         0         2  Slurping Turtle     3.5  \n",
       "2           3                0         4         1  Slurping Turtle     3.5  \n",
       "3        6682             6948       605       503  Slurping Turtle     3.5  \n",
       "4          22               24         3         7  Slurping Turtle     3.5  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "# 0 is NR, 1 is YR\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['flagged'] = le.fit_transform(df['flagged'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['reviewContent']\n",
    "y = df['flagged']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(471561,)\n",
      "(202098,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Good choice by our Chicago friends for our fin...\n",
       "1         Im not a Takashi fan so I was a bit hesitant a...\n",
       "2         I should have read the the 3 stars and below r...\n",
       "3         It must be called slurping turtle because thei...\n",
       "4         Im surprised this place is getting so many neg...\n",
       "                                ...                        \n",
       "673654    Michael James at Amp is awesome I moved to Nor...\n",
       "673655    This is by far the best and most consistent re...\n",
       "673656    If you want a great cajuncreole meal in Hampto...\n",
       "673657    UPDATE  Finally heard back from them A worker ...\n",
       "673658    COME JOIN IN THE CELEBRATION CALL 312 226 0340...\n",
       "Name: cleaned_text, Length: 673659, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "    no_punct = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    return no_punct\n",
    "df['cleaned_text'] = df['reviewContent'].apply(lambda x: remove_punctuation(x))\n",
    "df['cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \\r and \\n\n",
    "df['cleaned_text'] = df['cleaned_text'].str.replace(\"\\r\", \" \")\n",
    "df['cleaned_text'] = df['cleaned_text'].str.replace(\"\\n\", \" \")\n",
    "df['cleaned_text'] = df['cleaned_text'].str.replace(\"    \", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \" when quoting text\n",
    "df['cleaned_text'] = df['cleaned_text'].str.replace('\"', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercasing the text\n",
    "df['cleaned_text'] = df['cleaned_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_signs = list(\"?:!.,;\")\n",
    "df['cleaned_text'] = df['cleaned_text']\n",
    "\n",
    "for punct_sign in punctuation_signs:\n",
    "    df['cleaned_text'] = df['cleaned_text'].str.replace(punct_sign, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['cleaned_text'].str.replace(\"'s\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         good choice by our chicago friends for our fin...\n",
       "1         im not a takashi fan so i was a bit hesitant a...\n",
       "2         i should have read the the 3 stars and below r...\n",
       "3         it must be called slurping turtle because thei...\n",
       "4         im surprised this place is getting so many neg...\n",
       "                                ...                        \n",
       "673654    michael james at amp is awesome i moved to nor...\n",
       "673655    this is by far the best and most consistent re...\n",
       "673656    if you want a great cajuncreole meal in hampto...\n",
       "673657    update  finally heard back from them a worker ...\n",
       "673658    come join in the celebration call 312 226 0340...\n",
       "Name: cleaned_text, Length: 673659, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 673659/673659 [15:27<00:00, 726.65it/s]\n"
     ]
    }
   ],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "nrows = len(df)\n",
    "lemmatized_text_list = []\n",
    "\n",
    "for row in tqdm(range(0, nrows)):\n",
    "    \n",
    "    # Create an empty list containing lemmatized words\n",
    "    lemmatized_list = []\n",
    "    \n",
    "    # Save the text and its words into an object\n",
    "    text = df.loc[row]['cleaned_text']\n",
    "    text_words = text.split(\" \")\n",
    "\n",
    "    # Iterate through every word to lemmatize\n",
    "    for word in text_words:\n",
    "        lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "        \n",
    "    # Join the list\n",
    "    lemmatized_text = \" \".join(lemmatized_list)\n",
    "    \n",
    "    # Append to the list containing the texts\n",
    "    lemmatized_text_list.append(lemmatized_text)\n",
    "\n",
    "df['cleaned_text_lemma'] = lemmatized_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text_strip'] = df['cleaned_text_lemma'].apply(lambda x: \" \".join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\BD\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the stop words list\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the stop words in english\n",
    "stop_words = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BD\\Anaconda3\\lib\\site-packages\\tqdm\\std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a4c6798daad44719478bb5b292fe51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=673659, style=ProgressStyle(description_wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df['cleaned_text_stopwords'] = df['cleaned_text_strip'].swifter.apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         good choice chicago friends final meal head ai...\n",
       "1         im takashi fan bite hesitant go well im glad g...\n",
       "2         read 3 star review spent 180 include 18 tip 3 ...\n",
       "3         must call slurp turtle service slow turtle act...\n",
       "4         im surprise place get many negativemediocre re...\n",
       "                                ...                        \n",
       "673654    michael jam amp awesome move norfolk 2 years a...\n",
       "673655    far best consistent restaurant norfolk less do...\n",
       "673656    want great cajuncreole meal hampton roads big ...\n",
       "673657    update finally hear back worker leave vm cell ...\n",
       "673658    come join celebration call 312 226 0340 ticket...\n",
       "Name: cleaned_text_stopwords, Length: 673659, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_text_stopwords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('../data/cleaned_text.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_text_stopwords'], \n",
    "                                                    df['flagged'], \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter election\n",
    "ngram_range = (1,2)\n",
    "min_df = 10\n",
    "max_df = 1.\n",
    "max_features = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(572610, 300)\n",
      "(101049, 300)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "                        \n",
    "features_train = tfidf.fit_transform(X_train).toarray()\n",
    "labels_train = y_train\n",
    "print(features_train.shape)\n",
    "\n",
    "features_test = tfidf.transform(X_test).toarray()\n",
    "labels_test = y_test\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6046274579659373"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(features_train, labels_train)\n",
    "import numpy as np\n",
    "predicted = clf.predict(features_test)\n",
    "np.mean(predicted == labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6200655127710318"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf_sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42).fit(features_train, labels_train)\n",
    "\n",
    "predicted = clf_sgd.predict(features_test)\n",
    "np.mean(predicted == labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
